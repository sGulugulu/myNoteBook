### **1. 编程语言与并行计算基础**

#### **编程语言：C/C++**

- [x] **基础语法与数据结构**：你需要熟悉 C/C++ 的基本语法，如控制结构、函数、指针、数组、结构体等。
    
- [x] **动态内存管理**：掌握 `malloc`、`free` 和 `new`、`delete` 等内存管理方法，理解内存分配、内存泄漏问题。
    
- [x] **面向对象编程**（C++）：理解类、对象、继承、虚函数、模板等基本概念。
    


#### **并行计算基础**

- [x] **串行与并行的区别**：理解串行计算与并行计算的核心区别，了解并行计算能够带来的性能提升。
    
- [x] **并行计算模型**：
    
     - [ ] **SIMD**（Single Instruction Multiple Data）：指同一指令作用于多个数据，典型的 CPU 模型。
        
    - [ ] **SIMT**（Single Instruction Multiple Threads）：这是 CUDA 使用的模型，指每个线程执行相同的指令，但处理不同的数据。每个线程有自己的寄存器和局部内存。
        
- [ ]  **线程与进程的区别** : **进程是“资源包”，线程是“执行流”。进程隔离安全但笨重，线程高效共享但危险。**
  下面从几个核心维度进行详细对比：

|特性维度|进程|线程|
|---|---|---|
|**基本定义**|**资源分配的基本单位**。程序的一次执行实例，拥有独立的内存空间和系统资源。|**CPU调度的基本单位**。是进程中的一个执行流，共享进程的内存和资源。|
|**资源拥有**|拥有独立的**地址空间**、代码段、数据段、堆、栈、文件描述符等系统资源。|**共享**其所属进程的地址空间和大部分资源（如打开的文件、全局变量）。每个线程拥有自己独立的**栈、寄存器和程序计数器**。|
|**切换开销**|**开销大**（重量级）。需要切换内存地址空间、页表、文件描述符表等，涉及大量CPU上下文保存与恢复。|**开销小**（轻量级）。主要切换私有栈、寄存器和程序计数器，内存空间不变，因此更快。|
|**通信机制**|**复杂**。进程间通信需要进程间通信机制，如管道、消息队列、共享内存、信号量、Socket等，由操作系统内核介入。|**简单**。由于共享内存，线程间可以直接读写全局变量、堆数据等，但需要程序员使用**同步机制**（如互斥锁、信号量）来避免竞态条件。|
|**独立性与稳定性**|**独立性高**。一个进程崩溃通常不会影响其他进程，因为内存空间是隔离的。|**稳定性低**。一个线程崩溃（如非法内存访问）会导致其所属的**整个进程**崩溃，因为共享地址空间。线程之间缺乏保护。|
|**创建与销毁**|**速度慢**，资源消耗大。需要为新的进程分配独立的系统资源。|**速度快**，资源消耗小。主要是在进程内部分配栈等少量资源。|
|**并发性**|进程间可以并发执行（在多核CPU上可以是真正的并行）。|线程间可以并发/并行执行，且通信和数据共享效率远高于进程。|
- [ ] **多线程编程基本概念**：如线程同步、竞态条件、死锁等。
	
	- [ ] **线程同步（Thread Synchronization）**  
	  确保多个线程按照一定顺序执行，防止竞态条件，常用的同步机制包括：
	  - [ ] **互斥锁（Mutex）**
	  - [ ] **信号量（Semaphore）**
	  - [ ] **条件变量（Condition Variable）**
	
	- [ ] **竞态条件（Race Condition）**  
	  当多个线程同时访问共享资源，且至少有一个线程修改资源时，程序的执行结果依赖于线程的执行顺序，可能导致不一致的行为。
	
	- [ ] **死锁（Deadlock）**  
	  两个或更多线程在相互等待对方释放资源时，导致程序无法继续执行。死锁的四个条件：
	  - [ ] **互斥条件**
	  - [ ] **占有并等待**
	  - [ ] **不抢占**
	  - [ ] **循环等待**
	
	- [ ] **活锁（Livelock）**  
	  线程处于不断的相互响应中，但没有任何线程能够完成任务。
	
	- [ ] **阻塞（Blocking）与非阻塞（Non-blocking）**  
	  - [ ] **阻塞**：线程等待某个操作完成时进入等待状态。
	  - [ ] **非阻塞**：线程在等待操作时不会进入等待状态，通常通过轮询或回调处理。
	
	- [ ] **原子操作（Atomic Operations）**  
	  原子操作是不可分割的操作，确保操作在执行过程中不会被中断，用于避免竞态条件。
	
	- [ ] **线程池（Thread Pool）**  
	  预先创建多个线程并加入池中，任务到来时，线程池分配空闲线程执行任务，减少线程创建和销毁的开销。
	
	- [ ] **工作窃取（Work Stealing）**  
	  空闲线程从其他繁忙线程那里“窃取”任务，以平衡负载。
	
	- [ ] **局部性（Locality）**  
	  线程访问内存时，尽量访问临近的数据，优化缓存命中率。
	
	- [ ] **线程局部存储（Thread Local Storage, TLS）**  
	  每个线程都有独立的内存空间，用于存储线程私有的数据，避免与其他线程的数据冲突。
	
	- [ ] **并行度（Concurrency Level）**  
	  可以同时执行的任务数，在多核处理器上增加并行度通常能提高程序效率。
	
	- [ ] **条件竞争（Condition Variable）**  
	  允许线程在某个条件满足时继续执行，通常与互斥锁一起使用，帮助线程之间协调。
	
	- [ ] **内存屏障（Memory Barrier）**  
	  确保内存操作的顺序，避免编译器、处理器等进行乱序优化，保证多线程程序的正确性。
	
	- [ ] **非阻塞 I/O（Non-blocking I/O）**  
	  允许线程继续执行，不在 I/O 操作完成时阻塞，通常通过事件通知或回调机制实现。
	
	- [ ] **线程安全（Thread Safety）**  
	  确保多个线程并发访问同一资源时，程序仍能保持正确性。
	
	- [ ] **层级锁（Lock Hierarchy）**  
	  锁按照层级顺序获取，避免死锁。每个线程按照相同顺序获取锁，防止形成环形等待。
	
	- [ ] **内存一致性模型（Memory Consistency Model）**  
	  描述在多线程环境下，线程对共享内存的访问如何保证一致性。常见的模型包括强一致性、弱一致性、顺序一致性等。


#### **GPU 架构基础**

- [x]  **GPU vs CPU**：理解 CPU 和 GPU 在架构上的区别：
    
    -  [x] **CPU** 是通用计算器，适合处理复杂的控制流和串行计算。
        
    - [ ]  **GPU** 拥有大量的并行计算单元，适合处理大量相同或相似的计算任务。
        
- **GPU 核心组成**：
    
    -  [ ] **流多处理器**（SM）：GPU 的计算核心，每个 SM 包含多个处理单元。
        
    -  [ ] **CUDA 核心**：GPU 中的基本计算单元，类似于 CPU 中的 ALU（算术逻辑单元）。
        
    -  [ ] **内存层次结构**：包括全局内存、共享内存、常量内存、纹理内存等。
        

#### **安装 CUDA 环境**

-  [ ] **安装 CUDA Toolkit**：下载并安装合适版本的 CUDA Toolkit，并确保安装 GPU 驱动。你可以在 [NVIDIA 官网](https://developer.nvidia.com/cuda-toolkit)下载。
    
-  [ ] **IDE 设置**：使用支持 CUDA 的 IDE（如 Visual Studio、CLion 或使用命令行工具）。
    

---

### **2. CUDA 基础：第一个 CUDA 程序**

#### **CUDA 编程模型**

CUDA 编程模型基于 **SIMT**（Single Instruction, Multiple Threads），这是 GPU 并行计算的核心：

-  [ ] **线程（Thread）**：每个线程执行相同的指令，但处理不同的数据。
    
-  [ ] **线程块（Block）**：多个线程组成一个线程块。线程块内的线程可以共享内存并进行同步。
    
-  [ ] **网格（Grid）**：多个线程块组成一个网格。
    

#### **第一个 CUDA 程序：向量加法**

编写并理解一个简单的程序，例如 **向量加法**，该程序会将两个数组中的元素一一相加并存储到第三个数组。

#### **程序结构**

-  [ ] **主机代码（Host Code）**：运行在 CPU 上，负责分配内存、调用 GPU 核心等。
    
-  [ ] **设备代码（Device Code）**：运行在 GPU 上，通常是 **kernel 函数**。每个线程执行该函数，并使用输入数据生成输出。
    

#### **CUDA 内存管理**

-  [ ] **`cudaMalloc`**：分配设备内存（GPU 内存）。
    
-  [ ] **`cudaMemcpy`**：将数据从主机（CPU）内存复制到设备（GPU）内存，或者反向复制。
    
-  [ ] **`cudaFree`**：释放设备内存。
    

---

### **3. 深入理解 CUDA 核心概念**

#### **CUDA 内存管理**

CUDA 有多种类型的内存，每种内存的访问方式、速度、作用范围不同，掌握这些可以帮助你优化程序性能：

-  [ ] **全局内存**：可由所有线程访问，较慢，且需要避免内存访问冲突。
    
-  [ ] **共享内存**：同一线程块中的线程可以访问，速度较快，用于线程间的数据共享和同步。
    
-  [ ] **常量内存**：只读，适用于线程访问同一数据的场景，访问速度较快。
    
-  [ ] **寄存器**：每个线程拥有的内存，速度最快，但数量有限。过多的寄存器使用会导致线程并行度下降。
    

#### **内存访问优化**

-  [ ] **内存合并（Memory Coalescing）**：为了提高内存带宽，线程必须按照一定的模式（如顺序访问）访问全局内存。
    
-  [ ] **内存对齐**：确保数据按合适的边界对齐，以减少内存访问的延迟。
    
-  [ ] **避免内存冲突**：多线程访问同一内存时，可能会导致冲突，降低效率。
    

#### **线程同步**

-  [ ] **`__syncthreads()`**：在同一个线程块内，调用该函数可同步线程。它确保所有线程在某一时刻完成当前任务并等待其他线程。
    
-  [ ] **原子操作**：对于多个线程可能同时操作的共享数据，使用原子操作来避免冲突。例如，原子加法 `atomicAdd()`。
    

#### **线程与块的设计**

-  [ ] **线程块的设计**：通常要根据 GPU 的架构特性（如 SM 数量、每个 SM 中的线程数等）来合理设计线程块的大小。
    
-  [ ] **优化块与网格的维度**：要选择适当的线程数、块数和网格数，确保 GPU 的资源得到充分利用。
    

---

### **4. CUDA 高级编程：并行算法与优化**

#### **并行算法**

-  [ ] **并行扫描（Prefix Sum）**：一种常用的并行算法，处理前缀和的问题。适用于大量并行计算的场景，如排序和图形计算。
    
-  [ ] **矩阵乘法**：矩阵运算是 GPU 加速的经典应用之一。理解如何使用 CUDA 进行矩阵乘法运算，并优化内存访问。
    
-  [ ] **并行排序**：学习如何在 GPU 上实现并行排序算法，如 **Bitonic Sort** 和 **Radix Sort**。
    

#### **流与事件（Streams & Events）**

-  [ ] **CUDA Streams**：通过创建多个流，可以实现异步计算（例如，CPU 和 GPU 同时执行任务），提高程序的效率。
    
-  [ ] **CUDA Events**：用于测量程序的性能，记录操作的开始与结束时间。
    

#### **错误处理与调试**

-  [ ] **错误处理**：使用 `cudaGetErrorString()` 等函数捕获 CUDA 运行时错误，确保代码的健壮性。
    
-  [ ] **调试工具**：使用 **cuda-gdb** 和 **NVIDIA Nsight** 进行调试。cuda-gdb 类似于 gdb，但专门针对 GPU 代码。
    

---

### **5. 性能优化**

#### **内存访问优化**

-  [ ] **内存合并**：确保线程访问内存时按照一定的规则进行，以便内存访问的合并，提高带宽。
    
-  [ ] **共享内存使用**：合理利用共享内存减少对全局内存的访问，尽量避免线程间的数据冲突。
    

#### **避免线程分支**

-  [ ] **分支合并（Branch Divergence）**：在同一个线程块内，所有线程执行相同的指令，如果某些线程因条件语句跳转，可能导致性能下降。应尽量避免。
    

#### **优化并行度与资源利用**

-  [ ] **选择合适的线程块大小**：过小的块会导致资源浪费，过大的块可能导致某些资源无法充分利用。要根据 GPU 的计算资源进行优化。
    
-  [ ] **调整网格与块的维度**：通过调整线程块和网格的大小，确保最大化 GPU 的并行度。
    

---

### **6. 实践与项目**

#### **编写高效的 CUDA 程序**

通过多次实践来提升你的 CUDA 编程能力，以下是一些可以尝试的项目：

-  [ ] **矩阵乘法**：使用不同的优化技术（共享内存、合并内存访问等）实现高效的矩阵乘法。
    
-  [ ] **图像处理**：例如图像滤波、卷积等，利用 GPU 加速图像处理任务。
    
-  [ ] **深度学习框架**：学习如何通过 CUDA 加速神经网络的训练和推理。
    

#### **参与开源项目**

参与一些开源 CUDA 项目，或在 GitHub 上查找相关的开源项目进行贡献。这将帮助你更好地理解 CUDA 编程的实际应用。

---

### **7. 深入学习与前沿技术**

#### **并行计算的数学基础**

- **线性代数**：矩阵运算、向量运算等在 GPU 编程中广泛应用。
    
- **FFT（快速傅里叶变换）**：GPU 加速信号处理中的常见操作。
    
- **蒙特卡洛模拟**：在物理、金融等领域中，GPU 可以加速蒙特卡洛方法的计算。
    

#### **集成 CUDA 与其他框架**

- **CUDA 与深度学习框架**：如 TensorFlow、PyTorch、MXNet 等框架已经集成了 CUDA 加速功能，学习如何使用它们可以加速深度学习任务。
    
- **CUDA 与 OpenCL**：了解如何在同一应用中结合使用 CUDA 和 OpenCL，实现跨平台的并行计算。
    

---
### 额外知识:

- [ ] warp-specialization和multi-stage的含义及其比较

